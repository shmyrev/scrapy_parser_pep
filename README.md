# Асинхронный парсер PEP

Парсер создан на основе фреймворка Scrapy. Парсер собирает данные обо всех PEP документах, создаёт два файла. Первый файл содержит название, статус и номер документа. Второй файл содержит общее количество документов и подсчёт количества статусов.

## Технологии проекта

- Python — высокоуровневый язык программирования.
- Scrapy — фреймворк для веб-краулинга.

### Как запустить проект:

Клонировать репозиторий и перейти в него в командной строке:

```
https://github.com/BuriloT/scrapy_parser_pep.git
```

```
cd scrapy_parser_pep
```

Cоздать и активировать виртуальное окружение:

```
python3 -m venv env
```

```
source env/bin/activate
```

Установить зависимости из файла requirements.txt:

```
python3 -m pip install --upgrade pip
```

```
pip install -r requirements.txt
```

Выполнить команду:

```
scrapy crawl pep
```